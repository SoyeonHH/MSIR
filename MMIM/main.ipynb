{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch1.7.1_p37/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/ubuntu/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/ubuntu/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/ubuntu/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/ubuntu/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/ubuntu/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/ubuntu/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "from torch.utils.data import DataLoader\n",
    "from solver import Solver\n",
    "from config import get_args, get_config, output_dim_dict, criterion_dict\n",
    "from data_loader import get_loader\n",
    "from test_instance import TestMOSI, TestMOSEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # torch.set_default_tensor_type('torch.FloatTensor')\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to a pretrained word embedding file\n",
    "# word_emb_path = '/mnt/soyeon/workspace/glove.840B.300d.txt'\n",
    "word_emb_path = '/home/ubuntu/soyeon/glove.840B.300d.txt'\n",
    "assert(word_emb_path is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# username = Path.home().name\n",
    "# project_dir = Path(__file__).resolve().parent.parent\n",
    "# sdk_dir = project_dir.joinpath('CMU-MultimodalSDK')\n",
    "# data_dir = project_dir.joinpath('datasets')\n",
    "\n",
    "# sdk_dir = Path('/mnt/soyeon/workspace/multimodal/CMU-MultimodalSDK')\n",
    "# data_dir = Path('/mnt/soyeon/workspace/multimodal/datasets')\n",
    "sdk_dir = Path('/home/ubuntu/soyeon/CMU-MultimodalSDK')\n",
    "data_dir = Path('/home/ubuntu/soyeon/MSIR/datasets')\n",
    "\n",
    "data_dict = {'mosi': data_dir.joinpath('MOSI'), 'mosei': data_dir.joinpath(\n",
    "    'MOSEI'), 'ur_funny': data_dir.joinpath('UR_FUNNY')}\n",
    "optimizer_dict = {'RMSprop': optim.RMSprop, 'Adam': optim.Adam}\n",
    "activation_dict = {'elu': nn.ELU, \"hardshrink\": nn.Hardshrink, \"hardtanh\": nn.Hardtanh,\n",
    "                   \"leakyrelu\": nn.LeakyReLU, \"prelu\": nn.PReLU, \"relu\": nn.ReLU, \"rrelu\": nn.RReLU,\n",
    "                   \"tanh\": nn.Tanh}\n",
    "\n",
    "output_dim_dict = {\n",
    "    'mosi': 1,\n",
    "    'mosei_senti': 1,\n",
    "}\n",
    "\n",
    "criterion_dict = {\n",
    "    'mosi': 'L1Loss',\n",
    "    'iemocap': 'CrossEntropyLoss',\n",
    "    'ur_funny': 'CrossEntropyLoss'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    # Tasks\n",
    "    \"dataset\": \"mosi\",\n",
    "    \"data_path\": \"datasets\",\n",
    "\n",
    "    # Dropouts\n",
    "    \"dropout_a\": 0.1,\n",
    "    \"dropout_v\": 0.1,\n",
    "    \"dropout_prj\": 0.1,\n",
    "\n",
    "    # Architecture\n",
    "    \"multiseed\": True,\n",
    "    \"contrast\": True,\n",
    "    \"add_va\": True,\n",
    "    \"n_layer\": 1,\n",
    "    \"cpc_layers\": 1,\n",
    "    \"d_vh\": 16,\n",
    "    \"d_ah\": 16,\n",
    "    \"d_vout\": 16,\n",
    "    \"d_aout\": 16,\n",
    "    \"bidirectional\": True,\n",
    "    \"d_prjh\": 128,\n",
    "    \"pretrain_emb\": 768,\n",
    "\n",
    "    # Activations\n",
    "    \"mmilb_mid_activation\": \"ReLU\",\n",
    "    \"mmilb_last_activation\": \"Tanh\",\n",
    "    \"cpc_activation\": \"Tanh\",\n",
    "\n",
    "    # Training Setting\n",
    "    \"batch_size\": 32,\n",
    "    \"clip\": 1.0,\n",
    "    \"lr_main\": 1e-3,\n",
    "    \"lr_bert\": 5e-5,\n",
    "    \"lr_mmilb\": 1e-3,\n",
    "    \"alpha\": 0.1,\n",
    "    \"beta\": 0.1,\n",
    "    \"weight_decay_main\": 1e-4,\n",
    "    \"weight_decay_bert\": 1e-4,\n",
    "    \"weight_decay_club\": 1e-4,\n",
    "    \"optim\": \"Adam\",\n",
    "    \"num_epochs\": 40,\n",
    "    \"when\": 20,\n",
    "    \"patience\": 10,\n",
    "    \"update_batch\": 1,\n",
    "\n",
    "    # Logistics\n",
    "    \"log_interval\": 100,\n",
    "    \"seed\": 1111\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    \"\"\"string to boolean\"\"\"\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self, data, mode='train'):\n",
    "        \"\"\"Configuration Class: set kwargs as class attributes with setattr\"\"\"\n",
    "        self.dataset_dir = data_dict[data.lower()]\n",
    "        self.sdk_dir = sdk_dir\n",
    "        self.mode = mode\n",
    "        # Glove path\n",
    "        self.word_emb_path = word_emb_path\n",
    "\n",
    "        # Data Split ex) 'train', 'valid', 'test'\n",
    "        self.data_dir = self.dataset_dir\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Pretty-print configurations in alphabetical order\"\"\"\n",
    "        config_str = 'Configurations\\n'\n",
    "        config_str += pprint.pformat(self.__dict__)\n",
    "        return config_str\n",
    "\n",
    "\n",
    "def get_config(dataset='mosi', mode='train', batch_size=32):\n",
    "    config = Config(data=dataset, mode=mode)\n",
    "    \n",
    "    config.dataset = dataset\n",
    "    config.batch_size = batch_size\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading the data....\n",
      "train\n",
      "Training data loaded!\n",
      "valid\n",
      "Validation data loaded!\n",
      "test\n",
      "Test data loaded!\n",
      "Finish loading the data....\n"
     ]
    }
   ],
   "source": [
    "dataset = str.lower(args.dataset.strip())\n",
    "\n",
    "set_seed(args.seed)\n",
    "print(\"Start loading the data....\")\n",
    "train_config = get_config(dataset, mode='train', batch_size=args.batch_size)\n",
    "valid_config = get_config(dataset, mode='valid', batch_size=args.batch_size)\n",
    "test_config = get_config(dataset, mode='test',  batch_size=args.batch_size)\n",
    "\n",
    "# pretrained_emb saved in train_config here\n",
    "train_loader = get_loader(args, train_config, shuffle=True)\n",
    "print('Training data loaded!')\n",
    "valid_loader = get_loader(args, valid_config, shuffle=False)\n",
    "print('Validation data loaded!')\n",
    "test_loader = get_loader(args, test_config, shuffle=False)\n",
    "print('Test data loaded!')\n",
    "print('Finish loading the data....')\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# addintional appending\n",
    "args.word2id = train_config.word2id\n",
    "\n",
    "# architecture parameters\n",
    "args.d_tin, args.d_vin, args.d_ain = train_config.tva_dim\n",
    "args.dataset = args.data = dataset\n",
    "args.when = args.when\n",
    "args.n_class = output_dim_dict.get(dataset, 1)\n",
    "args.criterion = criterion_dict.get(dataset, 'MSELoss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/ubuntu/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "solver = Solver(args, train_loader=train_loader, dev_loader=valid_loader, test_loader=test_loader, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = solver.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:21<00:00,  1.89it/s]\n",
      "100%|██████████| 41/41 [00:25<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch  1 | Time 48.8909 sec | Valid Loss 0.8566 | Test Loss 0.9392\n",
      "--------------------------------------------------\n",
      "MAE:  0.9391528\n",
      "Correlation Coefficient:  0.755333239532547\n",
      "mult_acc_7:  0.3629737609329446\n",
      "mult_acc_5:  0.41836734693877553\n",
      "F1 score all/non0: 0.7898/0.7918 over 686/656\n",
      "Accuracy all/non0: 0.7901/0.7912\n",
      "--------------------------------------------------\n",
      "Saved model at pre_trained_models/MM.pt!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:21<00:00,  1.89it/s]\n",
      "100%|██████████| 41/41 [00:25<00:00,  1.61it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch  2 | Time 49.0569 sec | Valid Loss 0.8426 | Test Loss 0.9577\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:21<00:00,  1.90it/s]\n",
      "100%|██████████| 41/41 [00:25<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch  3 | Time 49.3721 sec | Valid Loss 0.7948 | Test Loss 0.7741\n",
      "--------------------------------------------------\n",
      "MAE:  0.77414805\n",
      "Correlation Coefficient:  0.7570627137874315\n",
      "mult_acc_7:  0.4446064139941691\n",
      "mult_acc_5:  0.5160349854227405\n",
      "F1 score all/non0: 0.8107/0.8254 over 686/656\n",
      "Accuracy all/non0: 0.8105/0.8247\n",
      "--------------------------------------------------\n",
      "Saved model at pre_trained_models/MM.pt!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:21<00:00,  1.89it/s]\n",
      "100%|██████████| 41/41 [00:25<00:00,  1.61it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch  4 | Time 49.0612 sec | Valid Loss 0.8010 | Test Loss 0.8798\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:21<00:00,  1.90it/s]\n",
      "100%|██████████| 41/41 [00:25<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch  5 | Time 48.8552 sec | Valid Loss 0.7263 | Test Loss 0.7359\n",
      "--------------------------------------------------\n",
      "MAE:  0.7358665\n",
      "Correlation Coefficient:  0.7750612027685916\n",
      "mult_acc_7:  0.47230320699708456\n",
      "mult_acc_5:  0.5524781341107872\n",
      "F1 score all/non0: 0.8181/0.8364 over 686/656\n",
      "Accuracy all/non0: 0.8192/0.8369\n",
      "--------------------------------------------------\n",
      "Saved model at pre_trained_models/MM.pt!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:21<00:00,  1.89it/s]\n",
      "100%|██████████| 41/41 [00:25<00:00,  1.60it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch  6 | Time 49.2005 sec | Valid Loss 0.7660 | Test Loss 0.7368\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:21<00:00,  1.89it/s]\n",
      "100%|██████████| 41/41 [00:25<00:00,  1.61it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch  7 | Time 48.8719 sec | Valid Loss 0.8066 | Test Loss 0.7451\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:21<00:00,  1.91it/s]\n",
      "100%|██████████| 41/41 [00:25<00:00,  1.61it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch  8 | Time 48.8006 sec | Valid Loss 0.7626 | Test Loss 0.8214\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:21<00:00,  1.89it/s]\n",
      "100%|██████████| 41/41 [00:25<00:00,  1.60it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch  9 | Time 49.2763 sec | Valid Loss 0.7738 | Test Loss 0.7432\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:21<00:00,  1.90it/s]\n",
      "100%|██████████| 41/41 [00:25<00:00,  1.60it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch 10 | Time 49.0904 sec | Valid Loss 0.8040 | Test Loss 0.7631\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:21<00:00,  1.88it/s]\n",
      "100%|██████████| 41/41 [00:25<00:00,  1.58it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch 11 | Time 49.5970 sec | Valid Loss 0.7530 | Test Loss 0.7523\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:21<00:00,  1.88it/s]\n",
      "100%|██████████| 41/41 [00:25<00:00,  1.60it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch 12 | Time 49.2314 sec | Valid Loss 0.7693 | Test Loss 0.7591\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:21<00:00,  1.90it/s]\n",
      "100%|██████████| 41/41 [00:25<00:00,  1.61it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch 13 | Time 48.9105 sec | Valid Loss 0.7308 | Test Loss 0.7778\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:21<00:00,  1.91it/s]\n",
      "100%|██████████| 41/41 [00:25<00:00,  1.60it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch 14 | Time 48.9292 sec | Valid Loss 0.7822 | Test Loss 0.7318\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:21<00:00,  1.90it/s]\n",
      "100%|██████████| 41/41 [00:25<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch 15 | Time 49.0583 sec | Valid Loss 0.7369 | Test Loss 0.7569\n",
      "--------------------------------------------------\n",
      "Best epoch: 5\n",
      "MAE:  0.7358665\n",
      "Correlation Coefficient:  0.7750612027685916\n",
      "mult_acc_7:  0.47230320699708456\n",
      "mult_acc_5:  0.5524781341107872\n",
      "F1 score all/non0: 0.8181/0.8364 over 686/656\n",
      "Accuracy all/non0: 0.8192/0.8369\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = solver.train_and_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./saved_models_MMIM_mosi.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./saved_models_MMIM_mosi.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/69 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 5, got 74",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-318748897697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtester\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestMOSI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtester\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtester\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msegment_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/soyeon/MSIR/MMIM/test_instance.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbert_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_sent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_sent_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_sent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_sent_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_sent_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvlens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_sent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_sent_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch1.7.1_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/soyeon/MSIR/MMIM/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences, visual, acoustic, v_len, a_len, bert_sent, bert_sent_type, bert_sent_mask, y, mem)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# (batch_size, emb_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0macoustic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macoustic_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macoustic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mvisual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisual_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch1.7.1_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/soyeon/MSIR/MMIM/modules/encoders.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, lengths)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mpacked_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch1.7.1_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch1.7.1_p37/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch1.7.1_p37/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch1.7.1_p37/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    178\u001b[0m             raise RuntimeError(\n\u001b[1;32m    179\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 180\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 5, got 74"
     ]
    }
   ],
   "source": [
    "segment_list = []\n",
    "tester = TestMOSI\n",
    "tester = tester(model)\n",
    "segment_list, preds, preds_2, preds_7 = tester.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Gold-truth\n",
    "labels = []\n",
    "labels_2 = []\n",
    "labels_7 = []\n",
    "with open(f\"../datasets/{args.dataset}.pkl\", \"rb\") as handle:\n",
    "    data = pickle.load(handle)\n",
    "\n",
    "test_data = data[\"test\"]\n",
    "\n",
    "video = set()\n",
    "count = 0\n",
    "\n",
    "for idx in range(len(test_data)):\n",
    "    (words, visual, acoustic), label, segment = test_data[idx]\n",
    "    if args.dataset == 'mosi':\n",
    "        assert segment_list[idx] == segment\n",
    "    else:\n",
    "        video_name = segment[0]\n",
    "        if video_name in video:\n",
    "            count += 1\n",
    "        else:\n",
    "            video.add(video_name)\n",
    "            count = 0\n",
    "        assert segment_list[idx] == segment\n",
    "\n",
    "    labels.append(label[0][0])\n",
    "\n",
    "    # label_2 appending\n",
    "    if label > 0:\n",
    "        labels_2.append('positive')\n",
    "    else:\n",
    "        labels_2.append('negative')\n",
    "    \n",
    "    # label_7 appending\n",
    "    if label < -15/7:\n",
    "        labels_7.append('very negative')\n",
    "    elif label < -9/7:\n",
    "        labels_7.append('negative')\n",
    "    elif label < -3/7:\n",
    "        labels_7.append('slightly negative')\n",
    "    elif label < 3/7:\n",
    "        labels_7.append('Neutral')\n",
    "    elif label < 9/7:\n",
    "        labels_7.append('slightly positive')\n",
    "    elif label < 15/7:\n",
    "        labels_7.append('positive')\n",
    "    else:\n",
    "        labels_7.append('very positive')\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact\n",
    "def get_predict_result(idx = range(len(segment_list))):\n",
    "    print(\"SEGMENT:\", segment_list[idx])\n",
    "    print(\"GOLD_VALUE:\", labels[idx])\n",
    "    print(\"GOLD_BINARY:\", labels_2[idx])\n",
    "    print(\"GOLD_7_CLASS:\", labels_7[idx])\n",
    "    print(\"PREDICTED_VALUE:\", preds[idx])\n",
    "    print(\"PREDICTED_BINARY:\", preds_2[idx])\n",
    "    print(\"PREDICTED _7_CLASS:\", preds_7[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(segment_list))\n",
    "print(len(labels))\n",
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "import pandas as pd\n",
    "\n",
    "d = {'segmentID': segment_list, 'labels': labels, 'labels_2': labels_2, 'labels_7': labels_7, 'preds': preds, 'preds_2': preds_2, 'preds_7': preds_7}\n",
    "df = pd.DataFrame(data=d)\n",
    "order = ['very negative', 'negative', 'slightly negative', 'Neutral', 'slightly positive', 'positive', 'very positive']\n",
    "\n",
    "fig1 = px.bar(df, x=\"labels_7\")\n",
    "fig2 = px.bar(df, x=\"preds_7\")\n",
    "\n",
    "fig1_traces = []\n",
    "fig2_traces = []\n",
    "\n",
    "for trace in range(len(fig1[\"data\"])):\n",
    "    fig1_traces.append(fig1[\"data\"][trace])\n",
    "for trace in range(len(fig2[\"data\"])):\n",
    "    fig2_traces.append(fig2[\"data\"][trace])\n",
    "\n",
    "this_figure = sp.make_subplots(rows=1, cols=2, subplot_titles=(\"Gold\", \"MIM\"))\n",
    "for traces in fig1_traces:\n",
    "    this_figure.append_trace(traces, row=1, col=1)\n",
    "for traces in fig2_traces:\n",
    "    this_figure.append_trace(traces, row=1, col=2)\n",
    "\n",
    "this_figure.update_layout(height=600, width=1500, title_text=\"CMU-MOSI 7 Class Sentiment Intensity\")\n",
    "this_figure.update_xaxes(categoryorder='array', categoryarray= order)\n",
    "this_figure.update_yaxes(range=[0,250])\n",
    "this_figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99b221e9db0318903f19c34b1ba0eab49364574753058918f60cea91a58935ca"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('pytorch1.7.1_p37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
