{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMU-MOSEI Preprocessing Script\n",
    "This script is used for generating RAW_PREPROCESSED data from the raw CMU-MOSEI data, you can download the raw dataset from:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from shutil import copyfile\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base input output path\n",
    "base_path = '../data/MOSEI_Raw' # MOSEI_Raw path\n",
    "base_out_path = './MOSEI_RAW_PROCESSED' # RAW_PREPROCESSED path\n",
    "\n",
    "# Derived input path for each modalities and label\n",
    "base_audio_path = f'{base_path}/Audio/WAV_16000'\n",
    "base_video_path = f'{base_path}/Videos/Full/Combined'\n",
    "base_text_path = f'{base_path}/Transcript/Combined'\n",
    "base_label_path = f'{base_path}/Labels'\n",
    "\n",
    "# Number of jobs to run extraction in parallel\n",
    "num_jobs = 32 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dfs = []\n",
    "for path in glob.glob(f'{base_label_path}/*.csv'):\n",
    "    dfs.append(pd.read_csv(path))\n",
    "    \n",
    "# Generate table\n",
    "df = pd.concat(dfs)\n",
    "df['uttr_id'] = df.apply(lambda x: f\"{str(x['Input.VIDEO_ID']).split('/')[-1]}_{x['Input.CLIP']}\" , axis='columns')\n",
    "ldf = df[['uttr_id', 'Answer.anger', 'Answer.disgust', 'Answer.fear', 'Answer.happiness', 'Answer.sadness', 'Answer.surprise']]\n",
    "ldf = (ldf.groupby('uttr_id').sum().applymap(lambda x: 1 if x > 0 else 0)).reset_index()\n",
    "ldf.columns = [column.replace('Answer.','') for column in ldf.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uttr_id</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happiness</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--qXJuDtHPw_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3g5yACwYnA_10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3g5yACwYnA_13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3g5yACwYnA_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3g5yACwYnA_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          uttr_id  anger  disgust  fear  happiness  sadness  surprise\n",
       "0   --qXJuDtHPw_5      0        0     0          1        0         0\n",
       "1  -3g5yACwYnA_10      0        0     1          1        1         0\n",
       "2  -3g5yACwYnA_13      0        0     0          0        0         0\n",
       "3   -3g5yACwYnA_2      0        0     1          1        1         0\n",
       "4   -3g5yACwYnA_3      0        0     0          1        1         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Timing & Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "def split_transcript(path):\n",
    "    rows = []\n",
    "    for line in open(path,'r').readlines():\n",
    "        row = list(filter(lambda x: len(x) > 0, line.split('___')))\n",
    "        rows.append(row[:5])\n",
    "    return rows\n",
    "        \n",
    "time_data = []\n",
    "for path in glob.glob(f'{base_text_path}/*'):\n",
    "    time_data += split_transcript(path)\n",
    "\n",
    "# Generate table\n",
    "df = pd.DataFrame(time_data)\n",
    "df.columns = ['video_id', 'clip_id', 'start', 'end', 'text']\n",
    "df['uttr_id'] = df.apply(lambda x: f\"{str(x['video_id']).split('/')[-1]}_{x['clip_id']}\" , axis='columns')\n",
    "tdf = df[['uttr_id', 'video_id', 'start', 'end', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uttr_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SqofxdeEcjg_0</td>\n",
       "      <td>SqofxdeEcjg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.838</td>\n",
       "      <td>As director of the National Institutes of Heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SqofxdeEcjg_1</td>\n",
       "      <td>SqofxdeEcjg</td>\n",
       "      <td>28.447</td>\n",
       "      <td>32.959</td>\n",
       "      <td>I guess on Leap Year it would be \"EDI 366\" but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SqofxdeEcjg_2</td>\n",
       "      <td>SqofxdeEcjg</td>\n",
       "      <td>33.246</td>\n",
       "      <td>60.416</td>\n",
       "      <td>The leadership that is in place, and about to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SqofxdeEcjg_3</td>\n",
       "      <td>SqofxdeEcjg</td>\n",
       "      <td>59.935</td>\n",
       "      <td>63.11</td>\n",
       "      <td>And that's at all levels within NIH.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SqofxdeEcjg_4</td>\n",
       "      <td>SqofxdeEcjg</td>\n",
       "      <td>62.11</td>\n",
       "      <td>75.372</td>\n",
       "      <td>Everything from the senior investigators, the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uttr_id     video_id   start     end  \\\n",
       "0  SqofxdeEcjg_0  SqofxdeEcjg     0.0  28.838   \n",
       "1  SqofxdeEcjg_1  SqofxdeEcjg  28.447  32.959   \n",
       "2  SqofxdeEcjg_2  SqofxdeEcjg  33.246  60.416   \n",
       "3  SqofxdeEcjg_3  SqofxdeEcjg  59.935   63.11   \n",
       "4  SqofxdeEcjg_4  SqofxdeEcjg   62.11  75.372   \n",
       "\n",
       "                                                text  \n",
       "0  As director of the National Institutes of Heal...  \n",
       "1  I guess on Leap Year it would be \"EDI 366\" but...  \n",
       "2  The leadership that is in place, and about to ...  \n",
       "3             And that's at all levels within NIH.\\n  \n",
       "4  Everything from the senior investigators, the ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Label, Timing, and Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = ldf.merge(tdf, on='uttr_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['start'] = mdf['start'].astype(float)\n",
    "mdf['end'] = mdf['end'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uttr_id</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happiness</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>video_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--qXJuDtHPw_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>--qXJuDtHPw</td>\n",
       "      <td>23.199</td>\n",
       "      <td>30.325</td>\n",
       "      <td>I see that a writer is somebody who has an inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3g5yACwYnA_10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3g5yACwYnA</td>\n",
       "      <td>82.753</td>\n",
       "      <td>100.555</td>\n",
       "      <td>Key is part of the people that we use to solve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3g5yACwYnA_13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3g5yACwYnA</td>\n",
       "      <td>119.919</td>\n",
       "      <td>125.299</td>\n",
       "      <td>They've been able to find solutions or at leas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3g5yACwYnA_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3g5yACwYnA</td>\n",
       "      <td>4.840</td>\n",
       "      <td>14.052</td>\n",
       "      <td>Key Polymer brings a technical aspect to our o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3g5yACwYnA_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3g5yACwYnA</td>\n",
       "      <td>13.211</td>\n",
       "      <td>27.521</td>\n",
       "      <td>We're a huge user of adhesives for our operati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          uttr_id  anger  disgust  fear  happiness  sadness  surprise  \\\n",
       "0   --qXJuDtHPw_5      0        0     0          1        0         0   \n",
       "1  -3g5yACwYnA_10      0        0     1          1        1         0   \n",
       "2  -3g5yACwYnA_13      0        0     0          0        0         0   \n",
       "3   -3g5yACwYnA_2      0        0     1          1        1         0   \n",
       "4   -3g5yACwYnA_3      0        0     0          1        1         0   \n",
       "\n",
       "      video_id    start      end  \\\n",
       "0  --qXJuDtHPw   23.199   30.325   \n",
       "1  -3g5yACwYnA   82.753  100.555   \n",
       "2  -3g5yACwYnA  119.919  125.299   \n",
       "3  -3g5yACwYnA    4.840   14.052   \n",
       "4  -3g5yACwYnA   13.211   27.521   \n",
       "\n",
       "                                                text  \n",
       "0  I see that a writer is somebody who has an inc...  \n",
       "1  Key is part of the people that we use to solve...  \n",
       "2  They've been able to find solutions or at leas...  \n",
       "3  Key Polymer brings a technical aspect to our o...  \n",
       "4  We're a huge user of adhesives for our operati...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract MOSEI multimodal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(base_out_path):\n",
    "    os.makedirs(base_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23259it [00:00, 54659.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 356 ms, sys: 88 ms, total: 444 ms\n",
      "Wall time: 458 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Text and label\n",
    "meta_dict = {}\n",
    "for row in tqdm(mdf.itertuples()):\n",
    "    id, labels, video_id, start, end, text = row[1], list(row[2:8]), row[8], float(row[9]), float(row[10]), row[11]\n",
    "    audio_path = f'{base_audio_path}/{video_id}.wav'\n",
    "    video_path = f'{base_video_path}/{video_id}.mp4'\n",
    "    text_path = f'{base_text_path}/{video_id}.txt'\n",
    "    \n",
    "    if os.path.exists(video_path) \\\n",
    "        and os.path.exists(audio_path) \\\n",
    "        and os.path.exists(text_path):\n",
    "        # Store id, text, and labels to metadata buffer\n",
    "        text = text.replace('\\n','')\n",
    "        meta_dict[id] = {\n",
    "            'text': text,\n",
    "            'label': labels\n",
    "        }\n",
    "\n",
    "# Save metadata\n",
    "pickle.dump(meta_dict, open(f'{base_out_path}/meta.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(file_name, sampling_time=None, limit_time=280):\n",
    "    vidcap = cv2.VideoCapture(file_name)\n",
    "    # Read FPS\n",
    "    (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "    if int(major_ver)  < 3 :\n",
    "        fps = vidcap.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "    else :\n",
    "        fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Read image data\n",
    "    sampling_rate = int(np.round(float(sampling_time) / 1000 * fps))\n",
    "    success, image = vidcap.read()\n",
    "    images, i = [], 0\n",
    "    while success:\n",
    "        if i % sampling_rate == 0:\n",
    "            images.append(image)\n",
    "        success, image = vidcap.read()\n",
    "        i += 1\n",
    "        if i == int(fps * limit_time):\n",
    "            break\n",
    "    return np.stack(images), int(1000 // sampling_time)\n",
    "\n",
    "def retrieve_audio_segment(signal, sr, start_time, end_time):\n",
    "    start_time = 0 if start_time < 0 else start_time\n",
    "    start_idx = int(sr * start_time)\n",
    "    end_idx = int(sr * end_time)\n",
    "    audio_segment = signal[start_idx:end_idx]\n",
    "    return audio_segment\n",
    "\n",
    "def retrieve_video_segment(frames, fps, start_time, end_time):\n",
    "    start_idx = int(fps * start_time)\n",
    "    end_idx = int(fps * end_time)\n",
    "    images = frames[start_idx:end_idx,:,:,:]\n",
    "    return images\n",
    "\n",
    "def dump_image(img_segment, out_path='./'):\n",
    "    for i in range(img_segment.shape[0]):\n",
    "        cv2.imwrite(f'./{out_path}/image_{i}.jpg', img_segment[i,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parallel(video_id, vdf):\n",
    "    try:\n",
    "        audio_path = f'{base_audio_path}/{video_id}.wav'\n",
    "        video_path = f'{base_video_path}/{video_id}.mp4'\n",
    "        text_path = f'{base_text_path}/{video_id}.txt'\n",
    "        if os.path.exists(video_path) \\\n",
    "            and os.path.exists(audio_path) \\\n",
    "            and os.path.exists(text_path):\n",
    "\n",
    "            # Load video and audio data\n",
    "            sr, signal  = wavfile.read(audio_path)\n",
    "            images, fps = read_video(video_path, sampling_time=500, limit_time=280) # the max utterance of MOSEI is at ~270 second,\n",
    "\n",
    "            if len(signal.shape) == 2:\n",
    "                signal = signal[:,0]\n",
    "\n",
    "            # Iterate over utterance\n",
    "            for row in vdf.itertuples():\n",
    "                id, labels, start, end, text = row[1], list(row[2:8]), float(row[9]), float(row[10]), row[11]\n",
    "\n",
    "                # Create directory\n",
    "                out_path = f'{base_out_path}/{id}'\n",
    "                if not os.path.exists(out_path):\n",
    "                    os.makedirs(out_path)\n",
    "                    \n",
    "                # Retrieve audio segment and dump\n",
    "                audio_segment = retrieve_audio_segment(signal, sr, start, end)\n",
    "                wavfile.write(f'./{out_path}/audio.wav', sr, audio_segment)\n",
    "\n",
    "                # Retrieve video segment and dump\n",
    "                video_segment = retrieve_video_segment(images, fps, start, end)\n",
    "                dump_image(video_segment, out_path)\n",
    "            return (0, video_id)\n",
    "        else:\n",
    "            return (1, video_id)\n",
    "    except:\n",
    "        return (2, video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 404 ms, sys: 244 ms, total: 648 ms\n",
      "Wall time: 28.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Process multimodal data over video_id in parallel\n",
    "# NOTE: This might take several hours to run, the time listed on this cell is for processing 32 video_ids with num_jobs=16\n",
    "status_codes = Parallel(n_jobs=num_jobs)(delayed(extract_parallel)(video_id, vdf) for video_id, vdf in mdf.groupby('video_id'))\n",
    "\n",
    "# Save and Process Log\n",
    "log_df = pd.DataFrame(status_codes)\n",
    "log_df.columns = ['status', 'video_id']\n",
    "log_df.to_csv('log_extract.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "status       \n",
       "0          32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the status, it should all return 0 for all the ids mentioned in split\n",
    "log_df.groupby('status').size().to_frame('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('mm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "64d056d71e7aeb9116d94ac7bda4302b01ed533a5bc1e5661d2a849fcd90d3e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
