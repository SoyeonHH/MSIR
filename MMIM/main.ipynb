{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch1.7.1_p37/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/ubuntu/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/ubuntu/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/ubuntu/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/ubuntu/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/ubuntu/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/ubuntu/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "from torch.utils.data import DataLoader\n",
    "from solver import Solver\n",
    "from config import get_args, get_config, output_dim_dict, criterion_dict\n",
    "from data_loader import get_loader\n",
    "from test_instance import TestMOSI, TestMOSEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # torch.set_default_tensor_type('torch.FloatTensor')\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to a pretrained word embedding file\n",
    "# word_emb_path = '/mnt/soyeon/workspace/glove.840B.300d.txt'\n",
    "word_emb_path = '/home/ubuntu/soyeon/glove.840B.300d.txt'\n",
    "assert(word_emb_path is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# username = Path.home().name\n",
    "# project_dir = Path(__file__).resolve().parent.parent\n",
    "# sdk_dir = project_dir.joinpath('CMU-MultimodalSDK')\n",
    "# data_dir = project_dir.joinpath('datasets')\n",
    "\n",
    "# sdk_dir = Path('/mnt/soyeon/workspace/multimodal/CMU-MultimodalSDK')\n",
    "# data_dir = Path('/mnt/soyeon/workspace/multimodal/datasets')\n",
    "sdk_dir = Path('/home/ubuntu/soyeon/CMU-MultimodalSDK')\n",
    "data_dir = Path('/home/ubuntu/soyeon/MSIR/datasets')\n",
    "\n",
    "data_dict = {'mosi': data_dir.joinpath('MOSI'), 'mosei': data_dir.joinpath(\n",
    "    'MOSEI'), 'ur_funny': data_dir.joinpath('UR_FUNNY')}\n",
    "optimizer_dict = {'RMSprop': optim.RMSprop, 'Adam': optim.Adam}\n",
    "activation_dict = {'elu': nn.ELU, \"hardshrink\": nn.Hardshrink, \"hardtanh\": nn.Hardtanh,\n",
    "                   \"leakyrelu\": nn.LeakyReLU, \"prelu\": nn.PReLU, \"relu\": nn.ReLU, \"rrelu\": nn.RReLU,\n",
    "                   \"tanh\": nn.Tanh}\n",
    "\n",
    "output_dim_dict = {\n",
    "    'mosi': 1,\n",
    "    'mosei_senti': 1,\n",
    "}\n",
    "\n",
    "criterion_dict = {\n",
    "    'mosi': 'L1Loss',\n",
    "    'iemocap': 'CrossEntropyLoss',\n",
    "    'ur_funny': 'CrossEntropyLoss'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    # Tasks\n",
    "    \"dataset\": \"mosi\",\n",
    "    \"data_path\": \"datasets\",\n",
    "\n",
    "    # Dropouts\n",
    "    \"dropout_a\": 0.1,\n",
    "    \"dropout_v\": 0.1,\n",
    "    \"dropout_prj\": 0.1,\n",
    "\n",
    "    # Architecture\n",
    "    \"multiseed\": True,\n",
    "    \"contrast\": True,\n",
    "    \"add_va\": True,\n",
    "    \"n_layer\": 1,\n",
    "    \"cpc_layers\": 1,\n",
    "    \"d_vh\": 16,\n",
    "    \"d_ah\": 16,\n",
    "    \"d_vout\": 16,\n",
    "    \"d_aout\": 16,\n",
    "    \"bidirectional\": True,\n",
    "    \"d_prjh\": 128,\n",
    "    \"pretrain_emb\": 768,\n",
    "\n",
    "    # Activations\n",
    "    \"mmilb_mid_activation\": \"ReLU\",\n",
    "    \"mmilb_last_activation\": \"Tanh\",\n",
    "    \"cpc_activation\": \"Tanh\",\n",
    "\n",
    "    # Training Setting\n",
    "    \"batch_size\": 32,\n",
    "    \"clip\": 1.0,\n",
    "    \"lr_main\": 1e-3,\n",
    "    \"lr_bert\": 5e-5,\n",
    "    \"lr_mmilb\": 1e-3,\n",
    "    \"alpha\": 0.1,\n",
    "    \"beta\": 0.1,\n",
    "    \"weight_decay_main\": 1e-4,\n",
    "    \"weight_decay_bert\": 1e-4,\n",
    "    \"weight_decay_club\": 1e-4,\n",
    "    \"optim\": \"Adam\",\n",
    "    \"num_epochs\": 40,\n",
    "    \"when\": 20,\n",
    "    \"patience\": 10,\n",
    "    \"update_batch\": 1,\n",
    "\n",
    "    # Logistics\n",
    "    \"log_interval\": 100,\n",
    "    \"seed\": 1111\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    \"\"\"string to boolean\"\"\"\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self, data, mode='train'):\n",
    "        \"\"\"Configuration Class: set kwargs as class attributes with setattr\"\"\"\n",
    "        self.dataset_dir = data_dict[data.lower()]\n",
    "        self.sdk_dir = sdk_dir\n",
    "        self.mode = mode\n",
    "        # Glove path\n",
    "        self.word_emb_path = word_emb_path\n",
    "\n",
    "        # Data Split ex) 'train', 'valid', 'test'\n",
    "        self.data_dir = self.dataset_dir\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Pretty-print configurations in alphabetical order\"\"\"\n",
    "        config_str = 'Configurations\\n'\n",
    "        config_str += pprint.pformat(self.__dict__)\n",
    "        return config_str\n",
    "\n",
    "\n",
    "def get_config(dataset='mosi', mode='train', batch_size=32):\n",
    "    config = Config(data=dataset, mode=mode)\n",
    "    \n",
    "    config.dataset = dataset\n",
    "    config.batch_size = batch_size\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading the data....\n",
      "Total number of 0 datapoints have been dropped.\n",
      "Dataset split\n",
      "Train Set: 1284\n",
      "Validation Set: 229\n",
      "Test Set: 686\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0263a7dce2842d593c6a8eb8296014d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2196017 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 words in the embedding file.\n",
      "train\n",
      "Training data loaded!\n",
      "valid\n",
      "Validation data loaded!\n",
      "test\n",
      "Test data loaded!\n",
      "Finish loading the data....\n"
     ]
    }
   ],
   "source": [
    "dataset = str.lower(args.dataset.strip())\n",
    "\n",
    "set_seed(args.seed)\n",
    "print(\"Start loading the data....\")\n",
    "train_config = get_config(dataset, mode='train', batch_size=args.batch_size)\n",
    "valid_config = get_config(dataset, mode='valid', batch_size=args.batch_size)\n",
    "test_config = get_config(dataset, mode='test',  batch_size=args.batch_size)\n",
    "\n",
    "# pretrained_emb saved in train_config here\n",
    "train_loader = get_loader(args, train_config, shuffle=True)\n",
    "print('Training data loaded!')\n",
    "valid_loader = get_loader(args, valid_config, shuffle=False)\n",
    "print('Validation data loaded!')\n",
    "test_loader = get_loader(args, test_config, shuffle=False)\n",
    "print('Test data loaded!')\n",
    "print('Finish loading the data....')\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# addintional appending\n",
    "args.word2id = train_config.word2id\n",
    "\n",
    "# architecture parameters\n",
    "args.d_tin, args.d_vin, args.d_ain = train_config.tva_dim\n",
    "args.dataset = args.data = dataset\n",
    "args.when = args.when\n",
    "args.n_class = output_dim_dict.get(dataset, 1)\n",
    "args.criterion = criterion_dict.get(dataset, 'MSELoss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(args, train_loader=train_loader, dev_loader=valid_loader, test_loader=test_loader, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = solver.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = solver.train_and_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./saved_models_MMIM_mosi.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./saved_models_MMIM_mosi.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_list = []\n",
    "tester = TestMOSI\n",
    "tester = tester(model)\n",
    "segment_list, preds, preds_2, preds_7 = tester.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Gold-truth\n",
    "labels = []\n",
    "labels_2 = []\n",
    "labels_7 = []\n",
    "with open(f\"../datasets/{args.dataset}.pkl\", \"rb\") as handle:\n",
    "    data = pickle.load(handle)\n",
    "\n",
    "test_data = data[\"test\"]\n",
    "\n",
    "video = set()\n",
    "count = 0\n",
    "\n",
    "for idx in range(len(test_data)):\n",
    "    (words, visual, acoustic), label, segment = test_data[idx]\n",
    "    if args.dataset == 'mosi':\n",
    "        assert segment_list[idx] == segment\n",
    "    else:\n",
    "        video_name = segment[0]\n",
    "        if video_name in video:\n",
    "            count += 1\n",
    "        else:\n",
    "            video.add(video_name)\n",
    "            count = 0\n",
    "        assert segment_list[idx] == segment\n",
    "\n",
    "    labels.append(label[0][0])\n",
    "\n",
    "    # label_2 appending\n",
    "    if label > 0:\n",
    "        labels_2.append('positive')\n",
    "    else:\n",
    "        labels_2.append('negative')\n",
    "    \n",
    "    # label_7 appending\n",
    "    if label < -15/7:\n",
    "        labels_7.append('very negative')\n",
    "    elif label < -9/7:\n",
    "        labels_7.append('negative')\n",
    "    elif label < -3/7:\n",
    "        labels_7.append('slightly negative')\n",
    "    elif label < 3/7:\n",
    "        labels_7.append('Neutral')\n",
    "    elif label < 9/7:\n",
    "        labels_7.append('slightly positive')\n",
    "    elif label < 15/7:\n",
    "        labels_7.append('positive')\n",
    "    else:\n",
    "        labels_7.append('very positive')\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact\n",
    "def get_predict_result(idx = range(len(segment_list))):\n",
    "    print(\"SEGMENT:\", segment_list[idx])\n",
    "    print(\"GOLD_VALUE:\", labels[idx])\n",
    "    print(\"GOLD_BINARY:\", labels_2[idx])\n",
    "    print(\"GOLD_7_CLASS:\", labels_7[idx])\n",
    "    print(\"PREDICTED_VALUE:\", preds[idx])\n",
    "    print(\"PREDICTED_BINARY:\", preds_2[idx])\n",
    "    print(\"PREDICTED _7_CLASS:\", preds_7[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(segment_list))\n",
    "print(len(labels))\n",
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "import pandas as pd\n",
    "\n",
    "d = {'segmentID': segment_list, 'labels': labels, 'labels_2': labels_2, 'labels_7': labels_7, 'preds': preds, 'preds_2': preds_2, 'preds_7': preds_7}\n",
    "df = pd.DataFrame(data=d)\n",
    "order = ['very negative', 'negative', 'slightly negative', 'Neutral', 'slightly positive', 'positive', 'very positive']\n",
    "\n",
    "fig1 = px.bar(df, x=\"labels_7\")\n",
    "fig2 = px.bar(df, x=\"preds_7\")\n",
    "\n",
    "fig1_traces = []\n",
    "fig2_traces = []\n",
    "\n",
    "for trace in range(len(fig1[\"data\"])):\n",
    "    fig1_traces.append(fig1[\"data\"][trace])\n",
    "for trace in range(len(fig2[\"data\"])):\n",
    "    fig2_traces.append(fig2[\"data\"][trace])\n",
    "\n",
    "this_figure = sp.make_subplots(rows=1, cols=2, subplot_titles=(\"Gold\", \"MIM\"))\n",
    "for traces in fig1_traces:\n",
    "    this_figure.append_trace(traces, row=1, col=1)\n",
    "for traces in fig2_traces:\n",
    "    this_figure.append_trace(traces, row=1, col=2)\n",
    "\n",
    "this_figure.update_layout(height=600, width=1500, title_text=\"CMU-MOSI 7 Class Sentiment Intensity\")\n",
    "this_figure.update_xaxes(categoryorder='array', categoryarray= order)\n",
    "this_figure.update_yaxes(range=[0,250])\n",
    "this_figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99b221e9db0318903f19c34b1ba0eab49364574753058918f60cea91a58935ca"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('pytorch1.7.1_p37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
