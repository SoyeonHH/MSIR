{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "from torch.utils.data import DataLoader\n",
    "from solver import Solver\n",
    "from config import get_args, get_config, output_dim_dict, criterion_dict\n",
    "from data_loader import get_loader\n",
    "from test_instance import TestMOSI, TestMOSEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # torch.set_default_tensor_type('torch.FloatTensor')\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to a pretrained word embedding file\n",
    "word_emb_path = '/mnt/soyeon/workspace/glove.840B.300d.txt'\n",
    "assert(word_emb_path is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# username = Path.home().name\n",
    "# project_dir = Path(__file__).resolve().parent.parent\n",
    "# sdk_dir = project_dir.joinpath('CMU-MultimodalSDK')\n",
    "# data_dir = project_dir.joinpath('datasets')\n",
    "sdk_dir = Path('/mnt/soyeon/workspace/multimodal/CMU-MultimodalSDK')\n",
    "data_dir = Path('/mnt/soyeon/workspace/multimodal/datasets')\n",
    "data_dict = {'mosi': data_dir.joinpath('MOSI'), 'mosei': data_dir.joinpath(\n",
    "    'MOSEI'), 'ur_funny': data_dir.joinpath('UR_FUNNY')}\n",
    "optimizer_dict = {'RMSprop': optim.RMSprop, 'Adam': optim.Adam}\n",
    "activation_dict = {'elu': nn.ELU, \"hardshrink\": nn.Hardshrink, \"hardtanh\": nn.Hardtanh,\n",
    "                   \"leakyrelu\": nn.LeakyReLU, \"prelu\": nn.PReLU, \"relu\": nn.ReLU, \"rrelu\": nn.RReLU,\n",
    "                   \"tanh\": nn.Tanh}\n",
    "\n",
    "output_dim_dict = {\n",
    "    'mosi': 1,\n",
    "    'mosei_senti': 1,\n",
    "}\n",
    "\n",
    "criterion_dict = {\n",
    "    'mosi': 'L1Loss',\n",
    "    'iemocap': 'CrossEntropyLoss',\n",
    "    'ur_funny': 'CrossEntropyLoss'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    # Tasks\n",
    "    \"dataset\": \"mosi\",\n",
    "    \"data_path\": \"datasets\",\n",
    "\n",
    "    # Dropouts\n",
    "    \"dropout_a\": 0.1,\n",
    "    \"dropout_v\": 0.1,\n",
    "    \"dropout_prj\": 0.1,\n",
    "\n",
    "    # Architecture\n",
    "    \"multiseed\": True,\n",
    "    \"contrast\": True,\n",
    "    \"add_va\": True,\n",
    "    \"n_layer\": 1,\n",
    "    \"cpc_layers\": 1,\n",
    "    \"d_vh\": 16,\n",
    "    \"d_ah\": 16,\n",
    "    \"d_vout\": 16,\n",
    "    \"d_aout\": 16,\n",
    "    \"bidirectional\": True,\n",
    "    \"d_prjh\": 128,\n",
    "    \"pretrain_emb\": 768,\n",
    "\n",
    "    # Activations\n",
    "    \"mmilb_mid_activation\": \"ReLU\",\n",
    "    \"mmilb_last_activation\": \"Tanh\",\n",
    "    \"cpc_activation\": \"Tanh\",\n",
    "\n",
    "    # Training Setting\n",
    "    \"batch_size\": 32,\n",
    "    \"clip\": 1.0,\n",
    "    \"lr_main\": 1e-3,\n",
    "    \"lr_bert\": 5e-5,\n",
    "    \"lr_mmilb\": 1e-3,\n",
    "    \"alpha\": 0.1,\n",
    "    \"beta\": 0.1,\n",
    "    \"weight_decay_main\": 1e-4,\n",
    "    \"weight_decay_bert\": 1e-4,\n",
    "    \"weight_decay_club\": 1e-4,\n",
    "    \"optim\": \"Adam\",\n",
    "    \"num_epochs\": 40,\n",
    "    \"when\": 20,\n",
    "    \"patience\": 10,\n",
    "    \"update_batch\": 1,\n",
    "\n",
    "    # Logistics\n",
    "    \"log_interval\": 100,\n",
    "    \"seed\": 1111\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    \"\"\"string to boolean\"\"\"\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self, data, mode='train'):\n",
    "        \"\"\"Configuration Class: set kwargs as class attributes with setattr\"\"\"\n",
    "        self.dataset_dir = data_dict[data.lower()]\n",
    "        self.sdk_dir = sdk_dir\n",
    "        self.mode = mode\n",
    "        # Glove path\n",
    "        self.word_emb_path = word_emb_path\n",
    "\n",
    "        # Data Split ex) 'train', 'valid', 'test'\n",
    "        self.data_dir = self.dataset_dir\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Pretty-print configurations in alphabetical order\"\"\"\n",
    "        config_str = 'Configurations\\n'\n",
    "        config_str += pprint.pformat(self.__dict__)\n",
    "        return config_str\n",
    "\n",
    "\n",
    "def get_config(dataset='mosi', mode='train', batch_size=32):\n",
    "    config = Config(data=dataset, mode=mode)\n",
    "    \n",
    "    config.dataset = dataset\n",
    "    config.batch_size = batch_size\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = str.lower(args.dataset.strip())\n",
    "\n",
    "set_seed(args.seed)\n",
    "print(\"Start loading the data....\")\n",
    "train_config = get_config(dataset, mode='train', batch_size=args.batch_size)\n",
    "valid_config = get_config(dataset, mode='valid', batch_size=args.batch_size)\n",
    "test_config = get_config(dataset, mode='test',  batch_size=args.batch_size)\n",
    "\n",
    "# pretrained_emb saved in train_config here\n",
    "train_loader = get_loader(args, train_config, shuffle=True)\n",
    "print('Training data loaded!')\n",
    "valid_loader = get_loader(args, valid_config, shuffle=False)\n",
    "print('Validation data loaded!')\n",
    "test_loader = get_loader(args, test_config, shuffle=False)\n",
    "print('Test data loaded!')\n",
    "print('Finish loading the data....')\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# addintional appending\n",
    "args.word2id = train_config.word2id\n",
    "\n",
    "# architecture parameters\n",
    "args.d_tin, args.d_vin, args.d_ain = train_config.tva_dim\n",
    "args.dataset = args.data = dataset\n",
    "args.when = args.when\n",
    "args.n_class = output_dim_dict.get(dataset, 1)\n",
    "args.criterion = criterion_dict.get(dataset, 'MSELoss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(args, train_loader=train_loader, dev_loader=valid_loader, test_loader=test_loader, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = solver.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = solver.train_and_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./saved_models_MMIM_mosi.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./saved_models_MMIM_mosi.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_list = []\n",
    "tester = TestMOSI\n",
    "tester = tester(model)\n",
    "segment_list, preds, preds_2, preds_7 = tester.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Gold-truth\n",
    "labels = []\n",
    "labels_2 = []\n",
    "labels_7 = []\n",
    "with open(f\"../datasets/{args.dataset}.pkl\", \"rb\") as handle:\n",
    "    data = pickle.load(handle)\n",
    "\n",
    "test_data = data[\"test\"]\n",
    "\n",
    "video = set()\n",
    "count = 0\n",
    "\n",
    "for idx in range(len(test_data)):\n",
    "    (words, visual, acoustic), label, segment = test_data[idx]\n",
    "    if args.dataset == 'mosi':\n",
    "        assert segment_list[idx] == segment\n",
    "    else:\n",
    "        video_name = segment[0]\n",
    "        if video_name in video:\n",
    "            count += 1\n",
    "        else:\n",
    "            video.add(video_name)\n",
    "            count = 0\n",
    "        assert segment_list[idx] == segment\n",
    "\n",
    "    labels.append(label[0][0])\n",
    "\n",
    "    # label_2 appending\n",
    "    if label > 0:\n",
    "        labels_2.append('positive')\n",
    "    else:\n",
    "        labels_2.append('negative')\n",
    "    \n",
    "    # label_7 appending\n",
    "    if label < -15/7:\n",
    "        labels_7.append('very negative')\n",
    "    elif label < -9/7:\n",
    "        labels_7.append('negative')\n",
    "    elif label < -3/7:\n",
    "        labels_7.append('slightly negative')\n",
    "    elif label < 3/7:\n",
    "        labels_7.append('Neutral')\n",
    "    elif label < 9/7:\n",
    "        labels_7.append('slightly positive')\n",
    "    elif label < 15/7:\n",
    "        labels_7.append('positive')\n",
    "    else:\n",
    "        labels_7.append('very positive')\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact\n",
    "def get_predict_result(idx = range(len(segment_list))):\n",
    "    print(\"SEGMENT:\", segment_list[idx])\n",
    "    print(\"GOLD_VALUE:\", labels[idx])\n",
    "    print(\"GOLD_BINARY:\", labels_2[idx])\n",
    "    print(\"GOLD_7_CLASS:\", labels_7[idx])\n",
    "    print(\"PREDICTED_VALUE:\", preds[idx])\n",
    "    print(\"PREDICTED_BINARY:\", preds_2[idx])\n",
    "    print(\"PREDICTED _7_CLASS:\", preds_7[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(segment_list))\n",
    "print(len(labels))\n",
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "import pandas as pd\n",
    "\n",
    "d = {'segmentID': segment_list, 'labels': labels, 'labels_2': labels_2, 'labels_7': labels_7, 'preds': preds, 'preds_2': preds_2, 'preds_7': preds_7}\n",
    "df = pd.DataFrame(data=d)\n",
    "order = ['very negative', 'negative', 'slightly negative', 'Neutral', 'slightly positive', 'positive', 'very positive']\n",
    "\n",
    "fig1 = px.bar(df, x=\"labels_7\")\n",
    "fig2 = px.bar(df, x=\"preds_7\")\n",
    "\n",
    "fig1_traces = []\n",
    "fig2_traces = []\n",
    "\n",
    "for trace in range(len(fig1[\"data\"])):\n",
    "    fig1_traces.append(fig1[\"data\"][trace])\n",
    "for trace in range(len(fig2[\"data\"])):\n",
    "    fig2_traces.append(fig2[\"data\"][trace])\n",
    "\n",
    "this_figure = sp.make_subplots(rows=1, cols=2, subplot_titles=(\"Gold\", \"MIM\"))\n",
    "for traces in fig1_traces:\n",
    "    this_figure.append_trace(traces, row=1, col=1)\n",
    "for traces in fig2_traces:\n",
    "    this_figure.append_trace(traces, row=1, col=2)\n",
    "\n",
    "this_figure.update_layout(height=600, width=1500, title_text=\"CMU-MOSI 7 Class Sentiment Intensity\")\n",
    "this_figure.update_xaxes(categoryorder='array', categoryarray= order)\n",
    "this_figure.update_yaxes(range=[0,250])\n",
    "this_figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "658084397260d4aab479b7df4163d6eb096562a13a5b5f6c649e3c1d5e34b6c2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
